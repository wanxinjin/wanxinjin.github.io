<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

    Wanxin Jin


  | videos

</title>
<!-- <meta name="description" content=""> -->

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒŸ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/posts/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/">
       <span class="font-weight-bold"></span>   Wanxin Jin
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/iris_lab/">
                IRIS Lab
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <article>
    <h4 id="table-of-contents">Table of Contents</h4>
<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<ul>
  <li><a href="#HybridReduction">Task-Driven Hybrid Model Reduction for Dexterous Manipulation</a></li>
  <li><a href="#LFDC">Learning from Human Directional Corrections</a></li>
  <li><a href="#LFSD">Learning from Sparse Demonstrations</a></li>
  <li><a href="#PDP">Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework</a></li>
  <li><a href="#SafePDP">Safe Pontryagin Differentiable Programming</a></li>
</ul>

<p><a name="HybridReduction"></a></p>

<p style="margin-bottom:2.0cm; margin-left: 1.5cm"> </p>

<p><br /></p>

<hr />

<h3 id="task-driven-hybrid-model-reduction-for-dexterous-manipulation"><a href="../td_hybridreduction" target="_blank"><b>Task-Driven Hybrid Model Reduction for Dexterous Manipulation</b></a></h3>
<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<center>
<p style="margin-bottom:0.5cm; margin-left: 0.0cm">
<img src="../blogs/TRO_HybridReduction/figures/turning_webpage2.gif" width="350" />
<img src="../blogs/TRO_HybridReduction/figures/moving_webpage2.gif" width="350" />
</p>
</center>

<div style="background-color:rgba(0, 0, 0, 0.0470588);  vertical-align: middle; padding:10px; padding-left: 20px; padding-right: -20px;">

<p align="left">
Arxiv: <a href="https://arxiv.org/abs/2211.16657" target="_blank">https://arxiv.org/abs/2211.16657</a> <br />
Code (Python): <a href="https://github.com/wanxinjin/Task-Driven-Hybrid-Reduction" target="_blank">https://github.com/wanxinjin/Task-Driven-Hybrid-Reduction</a> <br />
Webpage: <a href="https://wanxinjin.github.io/td_hybridreduction/" target="_blank">https://wanxinjin.github.io/td_hybridreduction/</a>
<details> <summary><span style="font-family:Georgia; font-size:1.0em;">Abstract (click to check abstract)</span></summary>
	<br />
In contact-rich tasks, like dexterous manipulation, the hybrid nature of
making and breaking contact creates challenges for model representation and
control. For example, choosing and sequencing contact locations for in-hand
manipulation, where there are thousands of potential hybrid modes, is not
generally tractable. In this paper, we are inspired by the observation that far
fewer modes are actually necessary to accomplish many tasks. Building on our
prior work learning hybrid models, represented as linear complementarity
systems, we find a reduced-order hybrid model requiring only a limited number
of task-relevant modes. This simplified representation, in combination with
model predictive control, enables real-time control yet is sufficient for
achieving high performance. We demonstrate the proposed method first on
synthetic hybrid systems, reducing the mode count by multiple orders of
magnitude while achieving task performance loss of less than 5%. We also apply
the proposed method to a three-fingered robotic hand manipulating a previously
unknown object. With no prior knowledge, we achieve state-of-the-art
closed-loop performance in less than five minutes of online learning.
</details>
</p>
</div>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<div style="text-align: right;"> <a href="#top">Back to Table of Contents</a> </div>

<p><a name="LFDC"></a></p>

<p style="margin-bottom:3.0cm; margin-left: 1.5cm"> </p>

<p><br /></p>

<hr />

<h3 id="-learning-from-human-directional-corrections-"><b> Learning from Human Directional Corrections </b></h3>
<p style="margin-bottom:0.7cm; margin-left: 1.5cm"> </p>

<center>
<iframe width="700" height="400" src="https://www.youtube.com/embed/Mwlwt055Tgg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</center>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<div style="background-color:rgba(0, 0, 0, 0.0470588);  vertical-align: middle; padding:10px; padding-left: 20px; padding-right: -20px;">


<p align="left">
Arxiv:  <a href="https://arxiv.org/abs/2011.15014" target="_blank">https://arxiv.org/abs/2011.15014</a> <br />
Code (Python): <a href="https://github.com/wanxinjin/Learning-from-Directional-Corrections" target="_blank">https://github.com/wanxinjin/Learning-from-Directional-Corrections</a> 
<details> <summary><span style="font-family:Georgia; font-size:1.0em;">Abstract (click to check abstract)</span></summary>
	<br />
This paper proposes a novel approach that enables a robot to learn an objective function incrementally from human directional corrections. Existing methods learn from human magnitude corrections; since a human needs to carefully choose the magnitude of each correction, those methods can easily lead to over-corrections and learning inefficiency. The proposed method only requires human directional corrections -- corrections that only indicate the direction of an input change without indicating its magnitude. We only assume that each correction, regardless of its magnitude, points in a direction that improves the robot's current motion relative to an unknown objective function. The allowable corrections satisfying this assumption account for half of the input space, as opposed to the magnitude corrections which have to lie in a shrinking level set. For each directional correction, the proposed method updates the estimate of the objective function based on a cutting plane method, which has a geometric interpretation. We have established theoretical results to show the convergence of the learning process. The proposed method has been tested in numerical examples, a user study on two human-robot games, and a real-world quadrotor experiment. The results confirm the convergence of the proposed method and further show that the method is significantly more effective (higher success rate), efficient/effortless (less human corrections needed), and potentially more accessible (fewer early wasted trials) than the state-of-the-art robot learning frameworks.
</details>
</p>
</div>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>
<div style="text-align: RIGHT"> <a href="#top">Back to Table of Contents</a> </div>

<p><a name="LFSD"></a></p>

<p style="margin-bottom:3.0cm; margin-left: 1.5cm"> </p>
<p><br /></p>

<hr />

<h3 id="-learning-from-sparse-demonstrations-"><b> Learning from Sparse Demonstrations </b></h3>
<p style="margin-bottom:0.7cm; margin-left: 1.5cm"> </p>

<center>
<iframe width="700" height="400" src="https://www.youtube.com/embed/BYAsqMxW5Z4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</center>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>

<div style="background-color:rgba(0, 0, 0, 0.0470588);  vertical-align: middle; padding:10px; padding-left: 20px; padding-right: -20px;">
<p align="left">
Arxiv:  <a href="https://arxiv.org/abs/2008.02159" target="_blank">https://arxiv.org/abs/2008.02159</a> <br />
Code (Python): <a href="https://github.com/wanxinjin/Learning-from-Sparse-Demonstrations" target="_blank">https://github.com/wanxinjin/Learning-from-Sparse-Demonstrations</a> 
<details> <summary><span style="font-family:Georgia; font-size:1.0em;">Abstract (click to check abstract)</span></summary>
	<br />
This paper develops the method of Continuous Pontryagin Differentiable Programming (Continuous PDP), which enables a robot to learn an objective function from a few sparsely demonstrated keyframes. The keyframes, labeled with some time stamps, are the desired task-space outputs, which a robot is expected to follow sequentially. The time stamps of the keyframes can be different from the time of the robot's actual execution. The method jointly finds an objective function and a time-warping function such that the robot's resulting trajectory sequentially follows the keyframes with minimal discrepancy loss. The Continuous PDP minimizes the discrepancy loss using projected gradient descent, by efficiently solving the gradient of the robot trajectory with respect to the unknown parameters. The method is first evaluated on a simulated robot arm and then applied to a 6-DoF quadrotor to learn an objective function for motion planning in unmodeled environments. The results show the efficiency of the method, its ability to handle time misalignment between keyframes and robot execution, and the generalization of objective learning into unseen motion conditions.
</details>
</p>
</div>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>
<div style="text-align: RIGHT"> <a href="#top">Back to Table of Contents</a> </div>

<p><a name="PDP"></a></p>
<p style="margin-bottom:3.0cm; margin-left: 1.5cm"> </p>

<p><br /></p>

<hr />

<h3 id="-pontryagin-differentiable-programming-an-end-to-end-learning-and-control-framework-"><b> Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework </b></h3>

<p style="margin-bottom:0.7cm; margin-left: 0.5cm"> </p>

<h4 id="neurips-2020-presentation">NeurIPS 2020 Presentation</h4>
<p style="margin-bottom:0.5cm; margin-left: 0.5cm"> </p>
<center>
	<div id="presentation-embed-38936632"></div>
<script src="https://slideslive.com/embed_presentation.js"></script>
<script>
  embed = new SlidesLiveEmbed("presentation-embed-38936632", {
    presentationId: "38936632",
    autoPlay: false,
    verticalEnabled: true,
  });
</script>
</center>

<p style="margin-bottom:1.7cm; margin-left: 0.5cm"> </p>

<h5 id="examples-of-using-pdp-to-solve-robotic-tasks">Examples of using PDP to solve robotic tasks</h5>
<p style="margin-bottom:0.5cm; margin-left: 0.5cm"> </p>

<div class="row">
    <div class="col-sm mt-2 mt-md-0">
<iframe width="360" height="202" src="https://www.youtube.com/embed/5Jsu772Sqcg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        <div class="caption">
            PDP for optimal control.
        </div>
    </div>

        <div class="col-sm mt-2 mt-md-0">
<iframe width="360" height="202" src="https://www.youtube.com/embed/awVNiCIJCfs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        <div class="caption">
            PDP for inverse reinforcement learning.
        </div>
    </div>

</div>

<div style="background-color:rgba(0, 0, 0, 0.0470588);  vertical-align: middle; padding:10px; padding-left: 20px; padding-right: -20px;">
<p align="left">
Arxiv:  <a href="https://arxiv.org/pdf/1912.12970" target="_blank">https://arxiv.org/pdf/1912.12970</a> <br />
Code (Python): <a href="https://github.com/wanxinjin/Pontryagin-Differentiable-Programming" target="_blank">https://github.com/wanxinjin/Pontryagin-Differentiable-Programming</a> 
<details> <summary><span style="font-family:Georgia; font-size:1.0em;">Abstract (click to check abstract)</span></summary>
	<br />
This paper develops a Pontryagin Differentiable Programming (PDP) methodology,
which establishes a unified framework to solve a broad class of learning and control
tasks. The PDP distinguishes from existing methods by two novel techniques: first,
we differentiate through Pontryaginâ€™s Maximum Principle, and this allows to obtain
the analytical derivative of a trajectory with respect to tunable parameters within an
optimal control system, enabling end-to-end learning of dynamics, policies, or/and
control objective functions; and second, we propose an auxiliary control system in
the backward pass of the PDP framework, and the output of this auxiliary control
system is the analytical derivative of the original systemâ€™s trajectory with respect
to the parameters, which can be iteratively solved using standard control tools. We
investigate three learning modes of the PDP: inverse reinforcement learning, system
identification, and control/planning. We demonstrate the capability of the PDP in
each learning mode on different high-dimensional systems, including multi-link
robot arm, 6-DoF maneuvering quadrotor, and 6-DoF rocket powered landing
</details>
</p>
</div>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>
<div style="text-align: RIGHT"> <a href="#top">Back to Table of Contents</a> </div>

<p><a name="SafePDP"></a></p>
<p style="margin-bottom:3.0cm; margin-left: 1.5cm"> </p>

<p><br /></p>

<hr />

<h3 id="-safe-pontryagin-differentiable-programming-"><b> Safe Pontryagin Differentiable Programming </b></h3>

<p style="margin-bottom:0.7cm; margin-left: 0.5cm"> </p>

<h5 id="neurips-2021-presentation">NeurIPS 2021 Presentation</h5>

<center>
<div id="presentation-embed-38968248"></div>
<script src="https://slideslive.com/embed_presentation.js"></script>
<script>
  embed = new SlidesLiveEmbed("presentation-embed-38968248", {
    presentationId: "38968248",
    autoPlay: false,
    verticalEnabled: true,
  });
</script>
</center>

<p style="margin-bottom:1.5cm; margin-left: 0.5cm"> </p>

<h5 id="examples-of-using-safe-pdp-to-solve-safety-critical-robotic-tasks">Examples of using Safe-PDP to solve safety-critical robotic tasks</h5>
<p style="margin-bottom:0.5cm; margin-left: 0.5cm"> </p>

<div class="row">
    <div class="col-sm mt-2 mt-md-0">
        <iframe width="360" height="202" src="https://www.youtube.com/embed/sC81qc2ip8U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        <div class="caption">
            Safe PDP for safe neural policy optimization.
        </div>
    </div>
    <div class="col-sm mt-2 mt-md-0">
          <iframe width="360" height="202" src="https://www.youtube.com/embed/vZVxgo30mDs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          <div class="caption">
            Safe PDP for safe motion planning.
        </div>
    </div>
</div>

<div class="row">
      <div class="col-sm mt-3 mt-md-0">
    </div>
      <div class="col-sm mt-3 mt-md-0">
        <iframe width="360" height="202" src="https://www.youtube.com/embed/OBiLYYlWi98" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        <div class="caption">
          Safe PDP for learning MPCs (i.e., jointly learning dynamics,  constraints, and control cost) from demonstrations.
      </div>
    </div>
    <div class="col-sm mt-3 mt-md-0">
    </div>
</div>

<div style="background-color:rgba(0, 0, 0, 0.0470588);  vertical-align: middle; padding:10px; padding-left: 20px; padding-right: -20px;">
<p align="left">
Arxiv:  <a href="https://arxiv.org/abs/2105.14937" target="_blank">https://arxiv.org/abs/2105.14937</a> <br />
Code (Python): <a href="https://github.com/wanxinjin/Safe-PDP" target="_blank">https://github.com/wanxinjin/Safe-PDP</a> 
<details> <summary><span style="font-family:Georgia; font-size:1.0em;">Abstract (click to check abstract)</span></summary>
	<br />
We propose a Safe Pontryagin Differentiable Programming (Safe PDP) methodology, which establishes a theoretical and algorithmic framework to solve a broad class of safety-critical learning and control tasks -- problems that require the guarantee of safety constraint satisfaction at any stage of the learning and control progress. In the spirit of interior-point methods, Safe PDP handles different types of system constraints on states and inputs by incorporating them into the cost or loss through barrier functions. We prove three fundamentals of the proposed Safe PDP: first, both the solution and its gradient in the backward pass can be approximated by solving their more efficient unconstrained counterparts; second, the approximation for both the solution and its gradient can be controlled for arbitrary accuracy by a barrier parameter; and third, importantly, all intermediate results throughout the approximation and optimization strictly respect the constraints, thus guaranteeing safety throughout the entire learning and control process. We demonstrate the capabilities of Safe PDP in solving various safety-critical tasks, including safe policy optimization, safe motion planning, and learning MPCs from demonstrations, on different challenging systems such as 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing.
</details>
</p>
</div>

<p style="margin-bottom:0.5cm; margin-left: 1.5cm"> </p>
<div style="text-align: RIGHT"> <a href="#top">Back to Table of Contents</a> </div>

<p style="margin-bottom:2.0cm; margin-left: 1.5cm"> </p>
<hr />
<p style="margin-bottom:2.0cm; margin-left: 1.5cm"> </p>


  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024   Wanxin Jin.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: January 18, 2024.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
